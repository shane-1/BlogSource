# 软件架构杂谈

## 非功能性需求分析

在考虑具体系统的非功能性需求，主要从以下几个角度定位分析：

### 性能需求角度

- 业务响应时间

系统需要的业务响应时间，特别针对系统核心、跨系统的复杂业务场景需要做到的业务低响应耗时需考虑以下非功能性需求：
在数据加载时利用懒加载，即永远优先加载用户只管感受最明显的部分，其余部分延迟加载或非用户需要不加载；利用缓存中间件、CDN或边缘计算组件来减少网络环境的时延和减轻系统处理负载；在流程设计中合理利用消息队列中间件来提升用户响应；在检索场景引入elastic search等搜索中间件来减少耗时等措施。在无法异步处理的但高耗时场景，合理利用进度条、预计耗时来减少用户等待焦虑。

- 业务量

	系统需要承载的业务量，并发数和最大用户数需要考虑以下非功能性需求：
复杂业务场景系统应该通过切面日志或日志采集等方式，引入业务处理全生命周期的业务交易监控。当面对高业务量场景（如秒杀）时，应该进行服务隔离，即高业务量场景的服务瘫痪不会导致系统的服务瘫痪。在业务复杂的系统中，应针对业务的核心程度进行等级划分，在系统资源耗尽时应该即使进行服务降级，保证核心服务能够优先处理。在意外流量较多导致系统过载甚至瘫痪时，也应该通过微服务组件进行服务熔断，防止对系统造成进一步破坏，帮助服务恢复。
在某些用户负载可能难以预料的SaaS应用中，在设计初期就应考虑无状态应用，通过容器、HPA等弹性功能来让应用具有水平扩缩的弹性能力以面对负载的业务量级变化。某些具有租户等级的SaaS应用，还应能限制不同分级的租户的业务量级。

- 数据处理

	考虑系统需要承载的数据量、未来的业务数据增长方式和对不同数据的存储方式以达到最佳的性能需求时需考虑以下非功能性需求：
	数据是应用程序的核心。持久化存储的选择应该根据以下具体的业务场景。例如，Mysql适用于大量结构化和事务操作的业务场景，MongoDB适用于文档数据和业务数据增长不受预测业务场景，Redis适用于对数据访问读写有较高需求且不包含复杂查询业务场景。根据具体的功能需求又可以有键值对数据库、关系数据库、图数据库、时序数据库、内存数据库等不同场景的持久化存储方式选择。针对云环境，又可以有公有云厂商提供的适合于复杂云环境的跨多地域的数据库。针对分布式，又有TiDB等面向分布式场景构建的数据库。

### 安全需求角度

安全需求应该是在系统架构全生命周期中应该考虑的非功能性需求。对于来自于互联网侧的流量应该采用零信任原则，对于需要在互联网侧需要传输的身份信息、身份凭证等敏感信息都应采用破解难度高的非对称加密，对于需要传递的其他数据也应签名校验防止中间人篡改。对于架构中需要引入的开源组件，也应该进行充分的安全性验证。同时对于用户权限进行严格控制、可信的授权管理、历史操作记录及日志留存和安全审计也应作为非功能性需求考虑之中。对于互联网端系统，更应该建立系统的安全基线，从而感知恶意攻击。在某些情况下，可以通过蜜罐等欺骗伪装技术，来侦测系统存在的潜在安全风险。

### 可靠性需求角度

对于应用系统而言可靠性应该是系统架构需要重点考虑的非功能性需求要素。在系统部署架构时，应该采用跨区域多中心高可用架构。同时应该在架构上增强系统本身的程序健壮性，在架构设计中合理利用软件设计的开闭原则OCP、里氏替换原则LSP、依赖倒置原则DIP、单一职责原则 SRP、接口隔离原则 ISP、迪米特法则LOD和合成复用原则 CRP。对于程序中可能出现的所有运行时异常，都应有对应的处理流程，同时应该有相关记录留存用于监控审计。

### 兼容性需求角度

对于应用系统兼容性的非功能性需求主要体现为应用系统对用户环境的兼容性和软件历史版本的兼容性。用户本身的环境是差距巨大的，所以应用系统架构技术栈兼容性应该是需要重点考虑的非功能性需求。系统应该尽量兼容主流操作系统的主流版本，如网页需要适配以Chromium为内核的Chrome、Edge和以Gecko为内核的Firefox，在某些情况下还需要兼容已经弃用的IE。而在有版本迭代或有替换关系的应用系统设计中，如何兼容软件的历史版本也是需要重点考虑的，如Office在2007版本后虽然重写了文件存储方式，但其仍兼容之前版本格式，甚至给旧版本Office增加了补丁以兼容新格式。特别是对于以承诺性为原则的SaaS应用，不轻易改变用户的使用习惯应该是需要重点考虑的非功能性需求，版本的切换对于用户来说应该是平滑的。

### 其他角度

对于一个应用系统，易用性角度的非功能性需求、可用性角度的非功能性需求、可维护性角度的非功能性需求和可测试性角度的非功能性需求同样十分重要。

## 秒杀系统杂谈

秒杀系统的核心主要是`瞬时的高并发`，面对该种业务场景，可以通过以下方式来支撑处理：

### 页面

首先需要对秒杀的页面做静态化处理，避免用户常规操作多次请求后端服务。同时可以通过CDN进行内容分发。这部分可以利用云厂商 CDN来实现相关功能，秒杀的页面直接缓存在CDN，保证用户重复刷新页面只从CDN中获取最新前端代码。为防止用户使用脚本，页面的秒杀按钮也会限制点击次数，点击后一段时间置灰或者显示刷新等待后台响应。

### 缓存

秒杀场景是一个标准的读多写少的场景，写数据库前需要知道当前库存是否足够，足够才允许下单。所以应该使用PaaS的Redis服务作为缓存，来返回当前的库存情况。

### 异步

秒杀场景中，并发量大的是秒杀功能，下单和支付功能实际并发量很小。所以，有必要把下单和支付功能从秒杀流程中拆分出来，特别是下单功能要做成异步处理的。而支付功能，是业务场景本身保证的异步。需要采用消息队列来处理瞬间提升的用户请求。由于秒杀场景对于可靠性要求相对不高，相较于RabbitMQ来说，具有更大吞吐量的的Kafka服务更适合作为消息队列处理。同时可以使用Kafka的延时队列来实现超时未支付订单的取消。

### 限流

由于用户会重复操作，特别是脚本用户。可以选择在网络服务的负载均衡器使用对于同个用户进行限流、同个IP进行限流和限制接口的总次数来限制并发量，这种限制可以有效提升系统稳定性。为了进一步限制异常流量，还可以使用验证码或者移动滑块过滤异常流量。

### 分布式锁

在秒杀时，请求会先访问缓存是否存在该商品。如果不存在就会去查下数据库。此时需要在该查询操作添加分布式锁，不然会导致大量请求同时直接访问数据库，导致缓存击穿。此时可以使Zookeeper的分布式锁来实现。该分布式锁应该采用自旋锁，在规定的时间段内不断休眠一段时间后尝试抢夺锁。为了进一步增加系统可靠性，在秒杀开始前可以对秒杀商品全部提前加载到缓存进行预热。

### 隔离影响

使用K8S的无状态应用单独部署秒杀服务后端，将秒杀业务和普通业务拆分，彻底隔离秒杀的影响范围。同时使用K8S的HPA服务，增加秒杀服务的弹性扩缩容能力，保证秒杀服务能够根据流量负载弹性的处理秒杀请求。同时可以使用微服务的服务熔断，熔断异常服务，防止对整体系统造成进一步影响。

##  云产品支撑秒杀系统

### 网络负载均衡器

前置负载均衡器对于秒杀活动建立单独的秒杀黑名单IP库，对于已经被检测出异常非法请求的用户ID和IP进行封禁，阻止其访问相关服务。同时完善负载均衡器的静态资源缓存功能，将秒杀页面直接放置在负载均衡器，减少对后台服务的访问压力。

### Redis

建立统一的秒杀活动专属Redis集群，隔离普通业务缓存和秒杀缓存，限制秒杀活动影响范围。同时对不存在商品也进行缓存预热，进一步防范缓存击穿。同时增加分布式自旋锁lua脚本，帮助项目组按需灵活的配置分布式锁。

### Kafka和Zookeeper

Kafka服务针对消息丢失问题，提供统一消息发送表，增加重试机制。针对重复消费问题，提供统一的消息处理表。同时增对上面可能出现的垃圾消息，设置最大尝试次数机制，减少垃圾消息。通过分布式协调框架Zookeeper，让其在多节点处理某个节点需要回滚库存时，通知其他节点刷新本地缓存。提供Zookeeper实现类，帮助快速构建可以解决高并发多线程并发访问共享资源的并发安全问题。

### 容器

针对秒杀活动进一步定制专属镜像，尽可能的精简镜像内容来减少容器启动时间。增加秒杀专属集群以进一步优化网络调用链路，进一步减少时延。

## 对于`1-5-10`目标，按层次结构设计实例：

> 1-5-10 一分钟发现 五分钟定位 10分钟恢复

### 后端服务

对于后端而言，核心是提升异常感知能力。除了最基础的围绕后端服务的CPU、内存、硬盘占用情况的监控体系。还应该具有后端接口级别的监控能力，通过统一的切面实现对所有后端接口监控。对于接口抛出的异常以error类型统一传输给日志采集，对于接口响应时间超过最大限时的接口也以error类型统一传输给日志采集。在五分钟内同一接口若出现三次报错则将相关堆栈信息通知到系统维护方定位分析，争取先于用户报障就能提前定位系统异常点。对于采集所有接口日志能够以接口调用链路形成实时监控图，按接口调用流程展现错误点，进而帮助快速分析定位故障点。

同时需要提升后台整体的系统健壮性，对于流程化的错误处理能够形成自愈脚本，出现对应错误后通知系统管理员确认后触发自愈脚本进行处理。基本架构采的跨区域多中心高可用架构，保证服务连续性。特别是在互联网等不可预测的流量场景，需采用无状态的后端服务架构，通过HPA等自动扩缩组件来应对可能变化的业务流量。合理利用微服务接口监控、服务熔断能力，通过服务回滚等方式实现10分钟修复异常服务的目标。

### 数据库服务

监控数据库各项性能指标，特别是对于SQL执行时间超过阈值的慢SQL做到监控报警给DBA处理。数据库采用集群方案部署以预防单点故障，对于数据库不能集群化部署的情况也应采用主从模式且能够做到故障转移。对于复杂的分布式数据库，使用开源时序数据库 Prometheus 作为监控和性能指标信息存储方案，使用 Grafana 作为可视化组件进行展示。通过Prometheus存储的各项监控指标，判断分布式数据库集群表现，做到提前预警通知DBA处理。

### 中间件

对于各种中间件服务，除了基础的监控能力外。对于缓存来说还应该对于缓存的命中率进行管理，对于长时间无命中的缓存应该进行自动清理。对于热点数据应该进行及时持久化，同时在缓存重启时应该及时还原上个时间节点保存的持久化缓存数据。对于一些时效性敏感度高的数据，应该缩短过期时间，避免由数据不一致导致的错误。对于消息中间件来说，提供统一消息发送表，增加重试机制。针对重复消费问题，提供统一的消息处理表。同时增对上面可能出现的垃圾消息，设置最大尝试次数机制，减少垃圾消息，提升消息中间件整体的健壮性。

### 前端服务

前端服务做到动静分离。静态页面访问路径短，访问速度快，几毫秒。动态页面访问路径长，访问速度相对较慢(数据库的访问，网络传输，业务逻辑计算)，几十毫秒甚至几百毫秒，对架构扩展性的要求更高。静态页面与动态页面以不同域名区分。这样可以提升系统的访问速度，提升资源利用率。引入微前端框架，每次前端更新采用灰度更新，如发生异常及时回滚更新的前端实例。

### 整体

生产环境引入混沌工程。了解系统的通常行为，在系统健康时对系统有一个坚实的理解将有助于诊断问题。模拟逼真的场景，专注于可能的失败和错误。使用真实情况进行测试，这将产生最准确的结果。最大限度地减少爆炸半径，混沌工程可能具有高度破坏性，最好能让使用该系统的人无法判断正在进行混沌实验。应实行冗余，以确保如果实验确实造成问题，服务仍然可用。建立系统各项服务的安全基线，出现异常报警通知管理员，提前预知可能的隐患位置。
